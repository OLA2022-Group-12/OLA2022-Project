{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae2163bd",
   "metadata": {},
   "source": [
    "# Stupid Learner Notebook\n",
    "\n",
    "### Introduction\n",
    "\n",
    "In the following notebook we will analyze the behaviour of a particular learner type called *Stupid Learner*.\n",
    "\n",
    "The name derives from the fact that it doesn't actually learn anything during each iteration of the simulation but it always subdivides the current total budget equally among the various products instead.\n",
    "\n",
    "### Walkthrough\n",
    "\n",
    "Since the learner doesn't change over time and its decision algorithm is quite easy we are going to vary the environmental conditions and observe how the \"*constant prediction algorithm*\" scores in different situations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd0f881",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ola2022_project.environment.environment import example_environment, Step\n",
    "from ola2022_project.simulation.simulation import simulation \n",
    "from ola2022_project.learners.stupid_learner import StupidLearner # TODO: Fix import strategy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e84832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used for quickly plotting an experiment onto a graph and showing it\n",
    "def plot_experiment(n_days, rewards_per_experiment):\n",
    "    # Calculating and shaping data that is going to be shown on the graph\n",
    "    rewards = np.array(rewards_per_experiment).reshape(n_days)\n",
    "    days = np.arange(1, n_days + 1, 1)\n",
    "    mean = [np.mean(rewards_per_experiment)] * n_days\n",
    "    # Creating a new figure and plotting the data onto it\n",
    "    plt.figure()\n",
    "    plt.plot(days, rewards, label = \"Experiment\", marker = \".\", linestyle = '-')\n",
    "    plt.plot(days, mean, label = 'Mean', linestyle = '--')\n",
    "    # Setting labels and showing the figure\n",
    "    plt.xlabel(\"days\")\n",
    "    plt.ylabel(\"reward\")\n",
    "    plt.legend(loc = \"upper right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13147ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Number Generator used as a source of randomness by the environment and the simulation\n",
    "rng = np.random.default_rng()\n",
    "# Arbitrary total budget and product prices\n",
    "total_budget = 100\n",
    "product_prices = [5, 25, 10, 15, 9]\n",
    "# Environment containing all of the contextual information\n",
    "env = example_environment(\n",
    "    rng = rng, \n",
    "    total_budget = total_budget, \n",
    "    product_prices = product_prices\n",
    ")\n",
    "# Simulation parameters\n",
    "n_experiments = 1\n",
    "n_days = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1512af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the simulation\n",
    "rewards_per_experiment = simulation(\n",
    "    rng,\n",
    "    env,\n",
    "    learner_factory = StupidLearner,\n",
    "    n_experiment = n_experiments,\n",
    "    n_days = n_days,\n",
    "    step = Step.ZERO\n",
    ")\n",
    "# Plotting the experiment\n",
    "plot_experiment(n_days, rewards_per_experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e965c73",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "As expected, the reward obtained by the learner fluctuates over time without any particular trend since we are making a constant prediction in a random environment.\n",
    "\n",
    "The variance of the rewards is high and there is little to no correlation between them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53172353",
   "metadata": {},
   "source": [
    "### Another scenario\n",
    "\n",
    "What if we take into consideration an enviroment where there is a great imbalance in the products' prices?\n",
    "\n",
    "Intuitively we would expect that the reward is lower since, each day, a fixed amount of the total budget gets \"wasted\" on the products with high prices that are way beyond the reservation prices of most customers.\n",
    "\n",
    "This would be true for all learners but it is more evident for this particular type of learner since it doesn't try to adapt to the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ae1993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a new environment\n",
    "new_product_prices = [5, 1, 80, 55, 8]\n",
    "new_env = example_environment(\n",
    "    rng = rng, \n",
    "    total_budget = total_budget, \n",
    "    product_prices = new_product_prices\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b178961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the new simulation\n",
    "new_rewards_per_experiment = simulation(\n",
    "    rng,\n",
    "    new_env,\n",
    "    learner_factory = StupidLearner,\n",
    "    n_experiment = n_experiments,\n",
    "    n_days = n_days,\n",
    ")\n",
    "# Plotting the experiment\n",
    "plot_experiment(n_days, new_rewards_per_experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e7fc2e",
   "metadata": {},
   "source": [
    "### Results \n",
    "\n",
    "We can see that the generated data supports our hypotesis and, in addition, we can even show that the increase in rewards generated by incrementing the total budget is smaller when the prices are imbalanced due to the reasons stated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8762cf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_budgets = 6\n",
    "budget_interval = 25\n",
    "inc_env = inc_new_env = np.array([])\n",
    "inc_rewards_per_experiment = inc_new_rewards_per_experiment = np.empty((0, n_days))\n",
    "# Creating the previous two environments with various total budgets\n",
    "for i in range(0, n_budgets):\n",
    "    inc_env = np.append(inc_env, example_environment(\n",
    "        rng = rng, \n",
    "        total_budget = total_budget + (i * budget_interval), \n",
    "        product_prices = product_prices\n",
    "    ))\n",
    "    inc_new_env = np.append(inc_new_env, example_environment(\n",
    "        rng = rng, \n",
    "        total_budget = total_budget + (i * budget_interval), \n",
    "        product_prices = new_product_prices\n",
    "    ))\n",
    "# Running their respective simulations\n",
    "for i in range(0, n_budgets):\n",
    "    inc_rewards_per_experiment = np.vstack([inc_rewards_per_experiment, simulation(\n",
    "        rng,\n",
    "        inc_env[i],\n",
    "        learner_factory = StupidLearner,\n",
    "        n_experiment = n_experiments,\n",
    "        n_days = n_days,\n",
    "    )])\n",
    "    inc_new_rewards_per_experiment = np.vstack([inc_new_rewards_per_experiment, simulation(\n",
    "        rng,\n",
    "        inc_new_env[i],\n",
    "        learner_factory = StupidLearner,\n",
    "        n_experiment = n_experiments,\n",
    "        n_days = n_days,\n",
    "    )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b54f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the comparison between the two averages in both cases\n",
    "budgets = [total_budget + i * budget_interval for i in range(0, n_budgets)]\n",
    "means = [np.mean(inc_rewards_per_experiment[i]) for i in range(0, n_budgets)]\n",
    "new_means = [np.mean(inc_new_rewards_per_experiment[i]) for i in range(0, n_budgets)]\n",
    "plt.figure()\n",
    "plt.plot(budgets, means, label = \"Balanced prices\", marker = \".\", linestyle = '-')\n",
    "plt.plot(budgets, new_means, label = \"Imbalanced prices\", marker = \".\", linestyle = '-')\n",
    "plt.xlabel(\"budgets\")\n",
    "plt.ylabel(\"mean reward\")\n",
    "plt.legend(loc = \"upper right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
